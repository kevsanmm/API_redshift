{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Encabezado del Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para procesamiento e inserción de datos de tasas de cambio en Redshift\n",
    "Este notebook obtiene datos de tasas de cambio de una API, los procesa y los inserta en una base de datos Redshift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Código para obtener datos (antes data_fetcher.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def obtener_datos():\n",
    "    # URL de la API\n",
    "    url = 'https://api.exchangerate-api.com/v4/latest/USD'\n",
    "    \n",
    "    # Realizar la solicitud GET\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error al obtener datos: {response.status_code}\")\n",
    "    \n",
    "    # Convertir la respuesta JSON a un diccionario\n",
    "    data = response.json()\n",
    "    \n",
    "    # Convertir los datos de tasas de cambio en un DataFrame\n",
    "    rates_df = pd.DataFrame(list(data['rates'].items()), columns=['Currency', 'Rate'])\n",
    "    \n",
    "    base_currency = data['base']\n",
    "    date = data['date']\n",
    "    \n",
    "    # Agregar columna de fecha\n",
    "    rates_df['Date'] = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    \n",
    "    return rates_df, base_currency, date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Código para procesar los datos (antes data_preprocessing.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def procesar_datos(rates_df, date):\n",
    "    specific_currencies = {'USD', 'ARS', 'AUD', 'BDT', 'BRL', 'CAD', 'CNY', 'ETB', 'EUR', 'FJD', 'GBP', 'HTG', 'JPY', 'NGN', 'NIO', 'PGK', 'PYG', 'SLL', 'VUV', 'ZAR'}\n",
    "    rates_df = rates_df[rates_df['Currency'].isin(specific_currencies)].copy()\n",
    "    \n",
    "    # Agregar columna temporal\n",
    "    rates_df['Ingestion_Time'] = datetime.now()\n",
    "    \n",
    "    # Diccionario de monedas a datos geográficos\n",
    "    currency_to_geo = {\n",
    "        'USD': {'Country': 'United States', 'Region': 'North America', 'Continent': 'America'},\n",
    "        'CAD': {'Country': 'Canada', 'Region': 'North America', 'Continent': 'America'},\n",
    "        # (continúa con los datos del diccionario que tienes)\n",
    "    }\n",
    "    \n",
    "    # Agregar datos geográficos\n",
    "    geo_data = rates_df['Currency'].map(currency_to_geo)\n",
    "    rates_df['Country'] = geo_data.apply(lambda x: x.get('Country') if isinstance(x, dict) else None)\n",
    "    rates_df['Region'] = geo_data.apply(lambda x: x.get('Region') if isinstance(x, dict) else None)\n",
    "    rates_df['Continent'] = geo_data.apply(lambda x: x.get('Continent') if isinstance(x, dict) else None)\n",
    "    \n",
    "    # Agregar columna Wealthy\n",
    "    wealthy_currencies = {'USD', 'CAD', 'BRL', 'ARS', 'AUD', 'FJD', 'JPY', 'CNY', 'EUR', 'GBP', 'ZAR', 'ETB'}\n",
    "    rates_df['Wealthy'] = rates_df['Currency'].apply(lambda x: 1 if x in wealthy_currencies else 0)\n",
    "    \n",
    "    rates_df = rates_df.drop_duplicates(subset=['Currency', 'Date'])\n",
    "    \n",
    "    return rates_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Código para conectar y manipular Redshift (antes utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "def conectar_redshift():\n",
    "    host = os.getenv('REDSHIFT_HOST')\n",
    "    port = os.getenv('REDSHIFT_PORT')\n",
    "    dbname = os.getenv('REDSHIFT_DBNAME')\n",
    "    user = os.getenv('REDSHIFT_USER')\n",
    "    password = os.getenv('REDSHIFT_PASSWORD')\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        dbname=dbname,\n",
    "        user=user,\n",
    "        password=password\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    return conn, cur\n",
    "\n",
    "def eliminar_registros(cur, rates_df):\n",
    "    delete_query = 'DELETE FROM exchange_rates WHERE currency = %s AND date = %s'\n",
    "    unique_keys = rates_df[['Currency', 'Date']].drop_duplicates()\n",
    "    for _, row in unique_keys.iterrows():\n",
    "        cur.execute(delete_query, (row['Currency'], row['Date']))\n",
    "\n",
    "def insertar_datos(cur, conn, rates_df, base_currency, date):\n",
    "    insert_query = '''\n",
    "    INSERT INTO exchange_rates (base, date, currency, rate, ingestion_time, country, region, continent, wealthy) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "    '''\n",
    "    for _, row in rates_df.iterrows():\n",
    "        cur.execute(insert_query, (\n",
    "            base_currency, row['Date'], row['Currency'], row['Rate'], row['Ingestion_Time'],\n",
    "            row['Country'], row['Region'], row['Continent'], row['Wealthy']\n",
    "        ))\n",
    "    conn.commit()\n",
    "\n",
    "def cerrar_conexion(cur, conn):\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Celda con la función principal (antes main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos insertados correctamente\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Obtener datos desde la API\n",
    "        rates_df, base_currency, date = obtener_datos()\n",
    "        \n",
    "        # Procesar los datos\n",
    "        rates_df = procesar_datos(rates_df, date)\n",
    "        \n",
    "        # Conectar a Redshift\n",
    "        conn, cur = conectar_redshift()\n",
    "        \n",
    "        try:\n",
    "            # Eliminar registros existentes\n",
    "            eliminar_registros(cur, rates_df)\n",
    "            \n",
    "            # Insertar nuevos datos\n",
    "            insertar_datos(cur, conn, rates_df, base_currency, date)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar los datos en Redshift: {e}\")\n",
    "            conn.rollback()  # Si algo falla, revertir los cambios\n",
    "        finally:\n",
    "            # Cerrar conexión\n",
    "            cerrar_conexion(cur, conn)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la función principal: {e}\")\n",
    "    else:\n",
    "        print(\"Datos insertados correctamente\")\n",
    "\n",
    "# Ejecutar el proceso\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
